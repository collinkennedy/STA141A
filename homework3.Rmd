---
title: "homework 3"
author: "Collin"
date: "11/12/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## **Homework 3**
### Multiple Linear Regression

**1)**
**a)**
```{r}
library(dplyr)
library(ggplot2)
set.seed(1)
n <- 100
x1 <- runif(n)
x2 <- runif(n,10,20)
y <- 2+2*x1+0.3*x2+rnorm(n)
trueRegDF = data.frame(x1 = x1, x2 = x2, y = y)

```
B0 = 2
B1 = 2
B2 = 0.3
sigma squared is 1

**b)**
```{r}
cor.test(x1,x2) #.017
ggplot(data = trueRegDF, mapping = aes(x = x1, y = x2))+
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)


```


**c)**
```{r}
reg1 = lm(y~x1+x2, data = trueRegDF)
summary(reg1)


```
B0,B1, and B2 are estimated to be 1.97, 1.93, and .30 respectively. These are all extremely close to the true values of the parameters. The residual standard error is .9675, which is close to the true value of sigma (1). 

I can reject the null hypothesis that x1 = 0, as well as the null hypothesis that x2 = 0. Both are highly statistically significant factors (this is consistent with the true model).

**d)**
```{r}
reg2 = lm(y~x1, data = trueRegDF)
summary(reg2)

```
B0 is estimated now to be 6.5.

B1 is estimated to be about 1.98.

The estimate for B0 is now nowhere near the true value of B0. The estimate for B1 is still close to the true value of B1. Again, I would reject the null hypothesis that B1 = 0, in favor of the alternative hypothesis that it does not equal 0. This is consistent with what we know about the true model.

The residual standard error is larger than in the model with all variables. It's also farther away from its true value (sigma is estimated to be 1.267, compared to the true value of sigma, which we know to be 1).

**e)**
```{r}
reg3 = lm(y~x2, data = trueRegDF)
summary(reg3)

```

The estimate for B0 is closer to its true value than in the previous model, but still not quite there. The estimate for B2 does appear to be close to its true value (estimated at .30467, whereas the true value is .3). The residual standard error is 1.094, which is closer to the true value of sigma. It is also an improvement in error compared to the previous model, which only included x1.


**2**
**a)**
```{r}
set.seed(1)
n <- 100
x1 <- runif(n)
x2 <- 0.5*x1+rnorm(n,0,.01)
y <- 2+2*x1+0.3*x2+rnorm(n)
trueRegDF2 = data.frame(x1 = x1, x2 = x2, y = y)

```


**(repeating)b)**
```{r}
cor.test(x1,x2)
ggplot(data = trueRegDF2, mapping = aes(x = x1, y = x2))+
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)


```

**(repeating)c)**
```{r}
reg4 = lm(y~x1+x2, data = trueRegDF2)
summary(reg4)

plot(reg4)


```
B0, B1, and B2 are estimated to be 2.1305, -1.7540, and 7.3967 respectively. I am unsure about whether or not these values or close to their true values, as I do not know the true values of the parameters, since the model was created from vectors of random samples. I cannot reject the null hypothesis that B1 = 0, nor the hypothesis that B2 = 0 at the 5% significance level. Notice that the standard errors for X1 and X2 are incredibly high, thanks to high multicollinearity. This harms the precision of our model.


**(repeating)d)**
```{r}
reg5 = lm(y~x1, data = trueRegDF2)
summary(reg5)


```
B0 and B1 are estimated to be 2.1172 and 1.9675 respectively. B0 is closer to its true value (2), and I can reject the null hypothesis that B1 = 0, in favor of the alternative hypothesis that it does not equal 0 at the %5 sig. level. The residual standard error, s, is close to 1, which is close to our value of sigma/ sigma-squared.


**(repeating)e)**
```{r}
reg6 = lm(y~x2, data = trueRegDF2)
summary(reg6)

```
B0 and B2 are estimated to be 2.1199 and 3.9273 respectively. Again, B0 is relatively close to its true value of 2. At the 5% significance level we reject the null hypothesis that B2 = 0 in favor of the alternative hypothesis that it does not equal 0. Similarly to the previous model, the residual standard error is 1.051, which is close to our value of sigma/sigma-squared.

The main difference between these models stems from how x2 is generated. Whereas in part 1 x2 and x1 are both generated from random samples from the uniform distribution, in part 2, x2 is sampled from a normal distribution.


**3** *What effect does this new observation have on the each of the models? In each model, is this observation an outlier? A high-leverage point?*
```{r}

x1 <- c(x1, 0.1)
x2 <- c(x2, 0.8)
y <- c(y, 6)

#now re-fitting
newRegDF = data.frame(x1 = x1, x2 = x2, y = y)

#repeating c)
fit1 = lm(y~x1+x2, data = newRegDF)
summary(fit1)


which.max(hatvalues(fit1)) #confirms my suspicion that 101st observation has high leverage
#it has the greatest leverage actually

par(mfrow = c(2,2))
plot(fit1)

library(car) 
influencePlot(fit1, id = "identify", main = 'Influence Plot')


```


The main difference I notice is that the standard errors for B1 and B2 are significantly lower here than in 2c, where we ran a regression of y on x1 and x2 (without these additional observations of x1 and x2). the R squared is also noticeably higher (.46 as opposed to .32, as seen in 2c.)

The additional observation is definitely an outlier and a high leverage point. We can see this in the scale location plot as well as the residuals vs leverage plot and residuals vs Fitted plot. Notice how the 101st observation passes the dashed line representing Cook's distance in the Residuals vs Leverage diagnostic plot.




```{r}
#repeating d)
 fit2 = lm(y~x1, data = newRegDF)
summary(fit2)
par(mfrow = c(2,2))
plot(fit2)

which.max(hatvalues(fit2))

```

Now that x2 is no longer included in the model, the diagnostic plots all look pretty standard. Looking at the normal qqplot, it appears it may still have a large residual(potential outlier). Based on the diagnostic plots, it doesn't look like it is highly influential.

I also do not think it is a high leverage point, as when i calculate the hatvalues (leverage points) of fit2, and then find the largest, it isn't that 101st observation anymore.


```{r}
fit3 = lm(y~x2,data =newRegDF)
summary(fit3)
par(mfrow = c(2,2))
plot(fit3)
which.max(hatvalues(fit3))


```
Unsurprisingly, the 101st observation has reappeared as potentially concerning, as seen in the diagnostic plots, but again it does not appear to be influential (since it doesn't cross the dashed line representing Cook's distance.) 

It is a high leverage point, but it is not an outlier based on the residuals vs leverage and normal qqplot.

